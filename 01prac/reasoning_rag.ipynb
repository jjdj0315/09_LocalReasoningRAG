{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB82Ll8c32lm"
      },
      "outputs": [],
      "source": [
        "%pip install -q langchain langgraph langchain-docling langchain-qdrant langchain-text-splitters langchain-ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nYUOlTSf32ln"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rOfmg5HT32ln"
      },
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "\n",
        "reasoning_llm = ChatOllama(\n",
        "    model=\"deepseek-r1:7b\",\n",
        "    stop=[\"</think>\"]\n",
        ")\n",
        "\n",
        "answer_llm = ChatOllama(\n",
        "    model=\"exaone3.5\",\n",
        "    temperature=0,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iBb5qxAp32lo"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated, List, TypedDict, Literal\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# RAG 상태 정의\n",
        "class RAGState(TypedDict):\n",
        "    \"\"\"RAG 시스템의 상태를 정의합니다.\"\"\"\n",
        "    query: str  # 사용자 질의\n",
        "    thinking: str  # reasoning_llm이 생성한 사고 과정\n",
        "    documents: List[Document]  # 검색된 문서\n",
        "    answer: str  # 최종 답변\n",
        "    messages: Annotated[List, add_messages]\n",
        "    mode: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cI3-c7Xz32lo",
        "outputId": "559de011-348d-4627-88af-f8a648b1b6e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/84/16/8416a7eb6bc0964a8abb5bb890afca2b8384fdc1e010a788e6c411a97c4d2305/3119563aab5a7c96fda4d621119b63fd8806272b86c30936d15507616422f718?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tableformer_fast.safetensors%3B+filename%3D%22tableformer_fast.safetensors%22%3B&Expires=1748435094&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0ODQzNTA5NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzg0LzE2Lzg0MTZhN2ViNmJjMDk2NGE4YWJiNWJiODkwYWZjYTJiODM4NGZkYzFlMDEwYTc4OGU2YzQxMWE5N2M0ZDIzMDUvMzExOTU2M2FhYjVhN2M5NmZkYTRkNjIxMTE5YjYzZmQ4ODA2MjcyYjg2YzMwOTM2ZDE1NTA3NjE2NDIyZjcxOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=UyjAuzsAZtZ6749wp8QBQepAbpP%7EY2XzpX4mIbboRIojY4kYfNLuD0UktnY14T1k95vzr5oiyzeXpSAY1EuKdIaos9NAVwCeuoMkELjvPxYIMtBSXfktT4uANfP5%7E%7E%7EI542VS27DAxQVsx1vcJVd-mGKhyMW9AK9Jvo9Ila8APUscVFu-uW6FWsOo1hSUgB7BogXKyWbENwnvxMV1h0ZB2Q7q9j2g4b-YRVMotahW4Ms0GVqoWzR6l6%7EDd4%7EEu34pXqbsogzbh5XdbW6TDN8-bzV111RoYgF5%7EVrH46276j0e1NG21itok-YsqiH4pM3cEOaNvkl6rcshvAwanxEzQ__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
            "Trying to resume download...\n",
            "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/84/16/8416a7eb6bc0964a8abb5bb890afca2b8384fdc1e010a788e6c411a97c4d2305/2a7d6c924b3cd12fb99a09280ca9c33a89c5d60b93253617d2e088c1a40374d9?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tableformer_accurate.safetensors%3B+filename%3D%22tableformer_accurate.safetensors%22%3B&Expires=1748436253&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0ODQzNjI1M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzg0LzE2Lzg0MTZhN2ViNmJjMDk2NGE4YWJiNWJiODkwYWZjYTJiODM4NGZkYzFlMDEwYTc4OGU2YzQxMWE5N2M0ZDIzMDUvMmE3ZDZjOTI0YjNjZDEyZmI5OWEwOTI4MGNhOWMzM2E4OWM1ZDYwYjkzMjUzNjE3ZDJlMDg4YzFhNDAzNzRkOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=OpPcEe4HubI%7EFe5Dxub6--JsGZmTZo75X3soWnIE73SatdFilk4ZvebRPaTT2ODSlJqW8NOwWcKzf63-vToD5sZNeodosfjTMU81KPGRyQUlYnOFrxP45w1-Ra8E54vtRbmg0b9%7EL8xrUSfa2O56YFEG0hBYTdiVA8bp1YnHnFoG5HY5VIAPsGVb%7EWBPmn26xWla07qWOMY8EkUlHR8PK7nfKpNLTZhVFu6RAHv32LCPAbrkdoFeqIVPCTLeZ90a-S1xsn00cFaaGQJFSNIYYC8Q5XGYPktIFymKmmDW2t53zWS6W4cHsNpoEiicHdejCJYoR-oEerFp-QxXG%7EAayg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
            "Trying to resume download...\n",
            "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/84/16/8416a7eb6bc0964a8abb5bb890afca2b8384fdc1e010a788e6c411a97c4d2305/31e60b4709571b613bc8736a9c982fb550d8d7a1809160a68a8282af60c8910b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1748434983&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0ODQzNDk4M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzg0LzE2Lzg0MTZhN2ViNmJjMDk2NGE4YWJiNWJiODkwYWZjYTJiODM4NGZkYzFlMDEwYTc4OGU2YzQxMWE5N2M0ZDIzMDUvMzFlNjBiNDcwOTU3MWI2MTNiYzg3MzZhOWM5ODJmYjU1MGQ4ZDdhMTgwOTE2MGE2OGE4MjgyYWY2MGM4OTEwYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Y%7ESyYurUngj%7EQONPi%7E0eptGbrSyxIbRC7STpaalvwVvemD36WSZmJZ1AgnK6pu0Zx%7EVeXW6tfnHAxY5WcCim-Stim5IaLqvgq8xQjKdk8nXYFcOGuEhUcrnfbssOGGZDcsLeWM3wAoKaio1eGgdPqg410KujhRQ%7EAYe4YTfj%7EBLEKHFi1dmidh%7EmgXQ9wSjjpNhDAXcnnRYFpy2j5gyFJcGJX3mmdxx1ng8CAUnfQwjYeCWC3MhvfX03Y6q1pNmcB4PAT%7E6Q8M%7EzvGWaUEOxKfzD4J9Uk1nM54zGyhWyLO-gRTfU8kkbNlnksUFkZLpcB8wz2ykrgkANw0kEDRES%7Ew__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
            "Trying to resume download...\n"
          ]
        }
      ],
      "source": [
        "from langchain_docling import DoclingLoader\n",
        "from langchain_docling.loader import ExportType\n",
        "\n",
        "FILE_PATH = \"https://arxiv.org/pdf/2408.09869\"\n",
        "\n",
        "loader = DoclingLoader(\n",
        "    file_path=FILE_PATH,\n",
        "    export_type=ExportType.MARKDOWN\n",
        "    )\n",
        "\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5RVkHdmD32lo",
        "outputId": "f664bc6f-7c6b-4f23-9b25-c67b7912d038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- d.page_content='Version 1.0  \\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar  \\nAI4K Group, IBM Research R¨ uschlikon, Switzerland'\n",
            "- d.page_content='This technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.'\n",
            "- d.page_content='Converting PDF documents back into a machine-processable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which discards most structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, cloud offerings [3] and most recently, multi-modal vision-language models. As of today, only a handful of open-source tools cover PDF conversion, leaving a significant feature and quality gap to proprietary solutions.  \\nWith Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.  \\nHere is what Docling delivers today:  \\n- · Converts PDF documents to JSON or Markdown format, stable and lightning fast\\n- · Understands detailed page layout, reading order, locates figures and recovers table structures\\n- · Extracts metadata from the document, such as title, authors, references and language\\n- · Optionally applies OCR, e.g. for scanned PDFs\\n- · Can be configured to be optimal for batch-mode (i.e high throughput, low time-to-solution) or interactive mode (compromise on efficiency, low time-to-solution)\\n- · Can leverage different accelerators (GPU, MPS, etc).'\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "\n",
        "splitter = MarkdownHeaderTextSplitter(\n",
        "    headers_to_split_on=[\n",
        "        (\"#\", \"Header_1\"),\n",
        "        (\"##\", \"Header_2\"),\n",
        "        (\"###\", \"Header_3\"),\n",
        "    ],\n",
        ")\n",
        "splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]\n",
        "\n",
        "for d in splits[:3]:\n",
        "    print(f\"- {d.page_content=}\")\n",
        "print(\"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1kFFyqb232lo",
        "outputId": "f927d21a-9430-4ba3-f529-11896e0095d3"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "In this section, we establish some reference numbers for the processing speed of Docling and the resource budget it requires. All tests in this section are run with default options on our standard test set distributed with Docling, which consists of three papers from arXiv and two IBM Redbooks, with a total of 225 pages. Measurements were taken using both available PDF backends on two different hardware systems: one MacBook Pro M3 Max, and one bare-metal server running Ubuntu 20.04 LTS on an Intel Xeon E5-2690 CPU. For reproducibility, we fixed the thread budget (through setting OMP NUM THREADS environment variable ) once to 4 (Docling default) and once to 16 (equal to full core count on the test hardware). All results are shown in Table 1.  \n",
              "If you need to run Docling in very low-resource environments, please consider configuring the pypdfium backend. While it is faster and more memory efficient than the default docling-parse backend, it will come at the expense of worse quality results, especially in table structure recovery.  \n",
              "Establishing GPU acceleration support for the AI models is currently work-in-progress and largely untested, but may work implicitly when CUDA is available and discovered by the onnxruntime and  \n",
              "torch runtimes backing the Docling pipeline. We will deliver updates on this topic at in a future version of this report.  \n",
              "Table 1: Runtime characteristics of Docling with the standard model pipeline and settings, on our test dataset of 225 pages, on two different systems. OCR is disabled. We show the time-to-solution (TTS), computed throughput in pages per second, and the peak memory used (resident set size) for both the Docling-native PDF backend and for the pypdfium backend, using 4 and 16 threads.  \n",
              "| CPU                         | Thread budget   | native backend   | native backend   | native backend   | pypdfium backend   | pypdfium backend   | pypdfium backend   |\n",
              "|-----------------------------|-----------------|------------------|------------------|------------------|--------------------|--------------------|--------------------|\n",
              "|                             |                 | TTS              | Pages/s          | Mem              | TTS                | Pages/s            | Mem                |\n",
              "| Apple M3 Max                | 4               | 177 s 167 s      | 1.27 1.34        | 6.20 GB          | 103 s 92 s         | 2.18 2.45          | 2.56 GB            |\n",
              "| (16 cores) Intel(R) E5-2690 | 16 4 16         | 375 s 244 s      | 0.60 0.92        | 6.16 GB          | 239 s 143 s        | 0.94 1.57          | 2.42 GB            |"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "display(Markdown(splits[12].page_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cuTZMzWK32lp"
      },
      "outputs": [],
      "source": [
        "from langchain_ollama import OllamaEmbeddings\n",
        "\n",
        "embeddings = OllamaEmbeddings(\n",
        "    model=\"bge-m3:latest\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u6OOBAew32lp"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "from langchain_qdrant import RetrievalMode\n",
        "\n",
        "vector_store = QdrantVectorStore.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"rag_collection_0228\",\n",
        "    retrieval_mode=RetrievalMode.DENSE\n",
        ")\n",
        "\n",
        "retriever = vector_store.as_retriever(search_kwargs = {'k':10})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CmR4R-K232lp"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
        "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
        "\n",
        "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-base\")\n",
        "\n",
        "compressor = CrossEncoderReranker(model=model, top_n=5)\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EvYUM8wG32lp"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "from langgraph.graph import START, StateGraph, END\n",
        "\n",
        "# 1. 질문 분류 함수 - 중요: 여기서는 상태를 업데이트하는 노드 함수\n",
        "def classify_node(state: RAGState):\n",
        "    \"\"\"질문을 분류하여 처리 모드를 결정합니다.\"\"\"\n",
        "    query = state[\"query\"]\n",
        "\n",
        "    if \"Docling\" in query:\n",
        "        print(\"=====검색 시작=====\")\n",
        "        return {\"mode\": \"retrieve\"}\n",
        "    else:\n",
        "        print(\"=====생성 시작=====\")\n",
        "        return {\"mode\": \"generate\"}\n",
        "\n",
        "\n",
        "# 2. 라우팅 함수 - 중요: 이 함수는 조건부 엣지에서 사용하며 문자열 반환\n",
        "def route_by_mode(state: RAGState) -> Literal[\"retrieve\", \"generate\"]:\n",
        "    \"\"\"모드에 따라 다음 단계를 결정합니다.\"\"\"\n",
        "    return state[\"mode\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def retrieve(state: RAGState):\n",
        "    \"\"\"질의를 기반으로 관련 문서를 검색합니다.\"\"\"\n",
        "    query = state[\"query\"]\n",
        "    print(\"=====검색 시작=====\")\n",
        "    documents = compression_retriever.invoke(query)\n",
        "    for doc in documents:\n",
        "        print(doc.page_content)\n",
        "        print(\"-\"*100)\n",
        "    print(\"=====검색 완료=====\")\n",
        "    return {\"documents\": documents}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def reasoning(state: RAGState):\n",
        "    \"\"\"쿼리를 분석하여 사고 과정을 생성합니다.\"\"\"\n",
        "    query = state[\"query\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
        "\n",
        "    reasoning_prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"주어진 문서를 활용하여 사용자의 질문에 가장 적절한 답변을 작성해주세요.\n",
        "\n",
        "        질문: {query}\n",
        "\n",
        "        문서 내용:\n",
        "        {context}\n",
        "\n",
        "\n",
        "        상세 추론:\"\"\"\n",
        "    )\n",
        "\n",
        "    reasoning_chain = reasoning_prompt | reasoning_llm | StrOutputParser()\n",
        "\n",
        "    print(\"=====추론 시작=====\")\n",
        "    thinking = reasoning_chain.invoke({\"query\": query, \"context\": context})\n",
        "\n",
        "    return {\"thinking\": thinking}\n",
        "\n",
        "\n",
        "\n",
        "# 3. 답변 생성 노드 (Answer LLM)\n",
        "def generate(state: RAGState):\n",
        "    \"\"\"문서와 추론 과정을 기반으로 최종 답변을 생성합니다.\"\"\"\n",
        "\n",
        "    query = state[\"query\"]\n",
        "    thinking = state.get(\"thinking\", \"\")  # get 메서드로 안전하게 접근\n",
        "    documents = state.get(\"documents\", [])  # get 메서드로 안전하게 접근\n",
        "\n",
        "    # 문서 내용 추출\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
        "\n",
        "    # 최종 답변 생성을 위한 프롬프트\n",
        "    answer_prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"사용자 질문에 한글로 답변하세요. 제공된 문서와 추론 과정이 있다면, 최대한 활용하세요.\n",
        "\n",
        "        질문:\n",
        "        {query}\n",
        "\n",
        "        추론 과정:\n",
        "        {thinking}\n",
        "\n",
        "        문서 내용:\n",
        "        {context}\n",
        "\n",
        "        답변:\"\"\"\n",
        "    )\n",
        "    print(\"=====답변 생성 시작=====\")\n",
        "\n",
        "    answer_chain = answer_prompt | answer_llm | StrOutputParser()\n",
        "\n",
        "    answer = answer_chain.invoke({\n",
        "        \"query\": query,\n",
        "        \"thinking\": thinking,\n",
        "        \"context\": context\n",
        "    })\n",
        "    print(\"=====답변 생성 완료=====\")\n",
        "    # 메시지에 답변 추가\n",
        "    return {\n",
        "        \"answer\": answer,\n",
        "        \"messages\": [HumanMessage(content=answer)]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3mCRHYBg32lp"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "workflow = StateGraph(RAGState)\n",
        "\n",
        "# 노드 추가\n",
        "workflow.add_node(\"classify\", classify_node)\n",
        "workflow.add_node(\"reasoning\", reasoning)\n",
        "workflow.add_node(\"retrieve\", retrieve)\n",
        "workflow.add_node(\"generate\", generate)\n",
        "\n",
        "# 엣지 추가\n",
        "workflow.add_edge(START, \"classify\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"classify\",\n",
        "    route_by_mode,  # 이 함수는 state[\"mode\"] 값을 반환\n",
        "    {\n",
        "        \"retrieve\": \"retrieve\",\n",
        "        \"generate\": \"generate\"\n",
        "    }\n",
        ")\n",
        "workflow.add_edge(\"retrieve\", \"reasoning\")\n",
        "workflow.add_edge(\"reasoning\", \"generate\")\n",
        "\n",
        "workflow.add_edge(\"generate\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "F7dNfoDq32lp",
        "outputId": "22807e13-034a-4334-a0ec-bd73b0bdc687"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJsAAAITCAIAAACff/lHAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXdcFMf7x+d64e4odxwdBUERlSLFGkUsxBhFiYld1BjEGE1iN8YWNcYWTVGx9xoL9m5sWAnSxQao9HoH1+vvj8uPL1Fg72Dv9nad98s/cHd29nP3uZlndnb3GZJerwcQAkHGWgAEZaCjRAM6SjSgo0QDOko0oKNEg4pKLcW5CmmtRlar1Wr0KrkOlTrNCoNFptBIbC6VzaO4tGZiLQdNSC25Hs1+WJOXKc3Lknp3siGRSGwexV5IV8q0qCo0C3QmRVSuktZoyGTSqwyJd0cb706cdiFcrHWhQDMdTb0peny1qk0Ax6uDjVdHGzMIsxw6HcjLlORny16m1Xb/VNCphy3WilqEyY4W5yku7i1uG8ztPlhAJlYUVit1985VFryQDxjn5OjGwFpOMzHN0Ywk8fN/aj+Z5MLiUMypCkukYu3ZHUVBvez8wnDZCZvg6PN/JEV58ojhjmaWZBVcO1TqG8Rt5c/GWojJGOvog4uVslpt5BdC80uyFi7vLxF6MIMj7LAWYhpGRcKXqRJRmfqDshMAEDXO+U2O9O0zGdZCTAPZUVG5+mWa5ONYZ4vosS6i493S7ojktTi4wq4D2dE7ieV+YTyLiLFGfIO5d06XY63CBBAcLcpVqJS61jgcIKBFuxBuZbGysliFtRBjQXD06cOaj4Z8EIPbJugZ7ZhxT4y1CmNpylGFVJuXLRF6WvRa++jRo0uWLGnGgf369SssLDSDIuDRlpV9X6zDweQmQHA0N1Pq1YFjQTEAAJCVldWMowoKCkQikRnk/ItXR05upsR89aNIU9ejN/8q8w7geLYzSxDNzc3dunVrcnIyhUIJCAgYN25cYGDgl19+mZaWZihw5MgRZ2fnAwcO3Lt3Lzc3VyAQRERExMfHM5lMAMDs2bPpdLqTk9P+/fvj4uK2bdtmOCoyMnLNmjXoq02XFuXKew4VoF4z+ugb5+Dq15XFyiYKNBulUtm/f/8ff/zxxYsXOTk5s2bNioyMVCgUer0+NjZ28eLFhmJbt27t0qXLtWvXHj9+fOPGjaioqD///NOwa/78+dHR0dOnT799+3Z1dfWdO3dCQkIKCgrMoVav1xfny49tfGumytGlqfuj0hoNm4fODdR3eP36dVVV1ahRo3x8fAAAq1evfvLkiUajYTD+E7PHjx/fv39/Ly8vw39TUlLu378/bdo0AACFQikvLz969Og7h5gJNpcqq9FY4EQtp1HDdFq9Wqljss1ye8XT09Pe3n7x4sWDBg0KCQkJCAgIDQ19vxiNRrt3797ixYtfvHih0WgAAI6O/xt4e3l5WcZOAIANlyKrxcfQqFHD9HpApZnrbhmDwdi+fXvPnj0PHjw4adKkYcOGXbp06f1iGzZs2LlzZ0xMzJkzZ5KTk8ePH/9OJWaS9z4kMqBQSRY7XUto1DMKlUQiAaXMXBNgrVu3/u67786dO7du3Tpvb+8ff/zx+fPn9QvodLrExMQvvvhi2LBhQqEQAFBbW2smMYhIa7QMFj7uBjelks2jSs0TPPLy8s6ePQsAYDKZERERq1evJpPJOTk59cuoVCqFQlHXzSqVyjt37phDjDHIajRsLj5uCTflqKs3y0zBo7q6etmyZRs3biwoKMjNzd21a5dOpwsICAAAeHh4ZGdnJycny+VyDw+Ps2fPGq41ly5dGhwcLBaLFQrF+xW2bt0aAHDt2rXmXc4iIpNonVuzzFEz6jTlqKMb/UWqWTq6zp07//DDDxcvXhw6dOgXX3yRnp6+detWgysxMTF6vf7rr79+9erVqlWraDTa8OHDhw4d2qNHj2nTptHp9MjIyIqKincqdHd3Hzx48JYtWzZt2mQOwS+eSJwsO3fWfJq4spGINLuW5FrwUsp62TLvpUqpw1qFUTTVRm1sKW4+bBzddjATRbmKtsFcGh0fY12ECQS/UG7SmYohU1wbKxAXF/fOGNWA4fKRSm24/nPnznE4ZpkxTk9PnzFjRoO7NBpNY3oAAH///TeJ1LBnSWfKew3DzQ0o5OeMTm0uDBvg4O7T8LigvLxcrVY3uEupVDZ2yejq2uhPpOUUFRU146jGJOVmSHOSaz6Z6NJiXRYC2dHyt6q0O9X9RjtZSpJ1cWlvSbdBAluBWWZDzQHyVbOjB93Fm/X3sTKL6LEuLu0t8Qnk4MhOY58F7NCVR6aS7p+vNL8eK+LmiXI7Ic0nyNJ3iFuICU9gp90WyWq13QbxzSzJKrh9slzowcTjY/UmzFUG9rKj0knndhTp8PSwo8moVfrEzYU8Pg2PdjbnTab8LOnFfSVh/RxC+9ubTRVmPLhY+fRhTf8xzu6++Jjze59mvm344EJl9sMavzCeV0cbArxRW/hKnp8lTbstCotyCOvnAPAxl9AwzX8jWK3QpyeJ8rKkonKVVwcOhUpicym2fJpahYNOmUojiyvVshqNHoCXqRKBG8O7o01ATzsyPu6vNEWL3vE2oJBqi/OVUrFaVqPVAyBH9XaNTqe7fPnywIEDUawTAMDiUkhkYMOl2thSXL1ZdCY+7n0aAwqOmhWVShUREXHv3j2sheAG4vw2IQago0QDOko0oKNEAzpKNKCjRAM6SjSgo0QDOko0oKNEAzpKNKCjRAM6SjSgo0QDOko0oKNEAzpKNKCjRAM6SjSgo0QDOko0oKNEAzpKNKzdURKJxGZ/uBm4m4G1O6rX62UynK3mgC3W7ijEVKCjRAM6SjSgo0QDOko0oKNEAzpKNKCjRAM6SjSgo0QDOko0oKNEAzpKNKCjRAM6SjSsNEPV1KlTHzx48E7ieDKZnJycjJ0ofGClbXT69Omurq7k/+Lk9IFmVjcJK3XU39+/c+fO9bdotdqQkBDsFOEGK3UUADBixAgXl/+t4ODq6jpu3DhMFeED63W0Y8eOhpXUDISGhvr6+mKqCB9Yr6MAgDFjxjg7OwMAhEIhbKBGYtWO+vv7BwYGAgDCw8MN60NDEDH56kVUpi4vVErEarXSEpc95eXlV65c+fjjj/l8S6xhQWOSuXZUR3emLR9Pa7zUxzRHH1yorChWAwAEbky1EgfZy02FziSXvVWQAHBuxcDp0gomOHr/QpVcoguLEphZklVw/1yZwI3ROcIWayEmY2wcTb8rllRrPxA7AQDdPhUW58qfJWO2cnizMc5RPci4Kw6McDC7HGsiKIKfdkeMtQqTMcpRhUwrk2hYHPwvnWEKPD6tokip1VjjvHcTGOWorFbL5uJ17NcS2DyKtMYsa9ObD6u+HoU0A+go0YCOEg3oKNGAjhIN6CjRgI4SDego0YCOEg3oKNGAjhIN6CjRsLSjS5fNmz3na3TrfP4ip0/f0KysdACAVCr9+ZfFgwb3WrDwO3TPgheIcEeF7yAYP26yQCAEAKSnp1y9euGbr2cFBYVirQsbCOEoXzBxQrzhb6lMCgDoP2AQj8vDWhc2mNHRpKRbf2xaW15e5tOmbcywkVFRn75T4P79Ozf+vpyWniKR1Lb36zhu7OSgoH/fg3jw4O6RY/uePct2dHTy9+/01Zff8PmCxrY/f5EzJX7sn7/vupt088jRfQCA6KGRoaFd09L+mTghftTIWEOdWq122Gf9d24/4ugoNN+nxhxzxdGkpFtLls2d/OU3P6/c2KNHxC9rlt74+0r9AjKZbMXPCzUazYL5P61cscHNzWPhou9FompDXFy4aGZoSNe9u098Hf/9ixc5635d0cT2OqbEzVj4wwoAwOnEG2tX/9mnz4DrNy7V7X2c/KC2tsbW1s5MH9lKMFcb3bVnS6+PIvv1/RgA0CW8u0RSK5NJ6xdgs9k7th9hs9iGr9jXx+/suZOZmWk9e0ZkZqQyGIwxoyeSSCSh0Kl9+465eS8BAI1tb4xPPxk247vJeXmvvLzaAABu374eFBhCp9PN9JGtBLM4qtPp8vJefRw1uG7L11O/f7+YTCrdsePPtPSUysoKwxaRuBoA0LFTkFwun//Dt+Gh3bp2+8jN1T04KLSJ7Y3RqVOQm5vH1WsX4r6artVq7ybdnDZ1phk+rnVhll5XoVDo9XoWq6nc1SUlxd9+P1mn0y3+cdXVyw8uXUiq29XW12/Vz7/xHQQJ234bO27o3HnfZGdnNLG9CaKHDL92/SIAIOXJY7VaFRHRH71PaaWYxVEGg0EikSSSph52vfH3ZbVaPW/u0oCAYCqV+k7hrl16zJ2z+NCBM/PnLq2qrlyw8DutVtvE9sYY0H9QdXVVypPHSUk3+/UdyGAw0PuUVopZHKVQKL4+7dLSU+q2JGz9bUvCxvplxGIRl8tjMpmG/968da1u15PU5MfJDwAAjo7CqKhPv546s6ZGXFZe2tj2JpTY2tr17tX36tULN/6+MnBgtBk+q9VhrrFuzLCRjx/fP3ps/5PU5MTTfx3764C3139eLvNp07aysuL8hUSNRvPgYVJmZirHhlNWVgIASE9/snjJ7HPnT4nFouynmadOHRUKnYSOTo1tb1rJoEHDrl2/6ODA92/f0Uwf1qow11g3KurTmlrx3n3bpFIpny+YGv/dO9ej/foNfP0mb/eehHXrV4SHd583Z8mBQ7v2H9gplUmnfDWjtrbmjz/Xrv91JZPJ7BMx4Nf1WykUyqiRsQ1ub1pJcFAonU7/5MNooMa+yVRVorq4t2RIvKdFJKFMdnbGt99/dfyvy7Y8k19LOvF7fsw0d54DnmbW8KTVVF68fFZWWrJtxx+jR01ohp04hciOJiRsTHnyOGrAp+PHfYW1FstBZEfXr9uCtQQMgHe8iQZ0lGhAR4kGdJRoQEeJBnSUaEBHiQZ0lGhAR4kGdJRoGOUog/1hZTKqg0QisfD22Y1y1IZHUUi1cgnOMvu0kJpKNZkMaEySEWWtCGN73YCeds+S8ZdSrSU8eyQO7IW/h3uNdTRsgL1Cosm6LzKzHmsh9WYVlUEK6Im/u6qm5de9dqhUD0gUKtnBhaFRETC/Lo1OrihS6DR6Kp3U53NHrOU0B5NzYBe+UpQXKOQSrVJmlKN5eXlyudzf37+5CltKenq6vb29h4eHMYUZHDLbhiL0YLp4Mc0vzSyYd02mFy9epKSkjBgxwnynMIb9+/f36tWrVatW2MqwDFa6yhak2ZhrhkGj0Xz22WdmqrwZqFSq4cOHY63CIujNw7p160QikZkqbx4lJSWbNm3CWoXZgb0u0UC/1922bduVK1eMKIgNZ86c2bdvH9YqzAjKjt65c8fNzW3AgAHoVosiQ4YM4XA4jx49wlqIuYC9LtFArY0WFhbOnTsXrdoswPTp06uqqrBWYQZQGV9pNJpZs2ahUpXFUKvVc+bMwVoF+sBel2ig0OuuXbv26dOnaIjBgNTU1N9//x1rFWjS0jZ6+PBhDw+Pnj17oifJ0ly/fl0sFsfExGAtBB1gr0s0mt/rpqWlbdlCnNf5NmzY8OzZM6xVoEHzBlQFBQVLlixBe5iGMXPmzKmsrMRaRUuBvS7RaE6vu2DBgpqaGjOIwZ7S0tLly5djraJFmOzoqlWrJk6cyOMRM3utk5NTdHT0hg0bsBbSfGCvSzRMaKPXr18/f/68OcVYESdPnrx79y7WKpqDsY4+evQoMzNz0KBBZtZjLcTExCQlJaWnp2MtxGRgr0s0kNuoUqlcsmSJRcRYI/Pnz8dagmkgO7p7924vLy+LiLFGvLy89uzZg7UKE0DudWUyGYlEYrFYlpJkXeDu48M4SjSQe929e/ceOnTIImKskV27dh09ehRrFSaAnOlRLper1WqLiLFG5HI5mYyn3AYwjiKAu48P4yjRgHEUARhHiQYB46hCoQAA1C3M8qGBu48P4yjRQO5P9uzZc+DAAYuIsUZ27Nhx5MgRrFWYAHIcVSgUVCqRFyhoGqVSia+PD+MoArj7+DCOEg0YRxGAcZRoEDCOKpVKEolE+OWv36Fv375isVir1VIoFMNXpNfrBQKBNaeYMIDc6zIYjA/NTgBAWFiYXq83LIVJIpFIJBIAIDIyEmtdyCA7umvXrv3791tEjBUxZswYFxeX+ls8PT0///xz7BQZC7KjKpVKqVRaRIwV0alTp4CAgPpbunTp0qZNG+wUGQtyzJ84caKhz/nQGDlyZGZmZlFREQDA3d195MiRWCsyChhHGyUgIKBdu3aGv8PCwvDyQCSMo00xbtw4Pp/v7u4+evRorLUYC3Kvq1KpdDprSXctKlOXFyklIo1aaRlJ7mE+o5hMZvlz2/Lnlkh+RGdSuPYUR3dmsxcPR74eVavVJBLJGq6yH12uKi9Q6QFwdGeqFNbyI0MXOpNc9kZOIpHcfZlBvZuz7gFu5nX/uS6qLlN3+QSXueObwe0TpV7+bP+uXFMPRI6jO3bs2Lt3b3OFocPTR7Wlb5Qfjp0AgF6fOT1PleRlSk09ENlRjUaD8XNGepB2RxQU4YClBiwIinBIvWXycizI0fHLL7/E9npUo9aLK9RcBxqGGjDBXkgvfa0w9SjkNkqj0bAdFklrNCwbnC1ehgpkColMIynlpo0B8RFHIcaD3Pg0Go1FlEDQAQdxFGISyI7SaB/ckATXIMfR7du34+u19Q8c5Daq1Wphr4sjkB2dPHkydBRHIDtqDXP0EOOBcZRowDhKNGAcJRowjhIN5Di6bdu2Xbt2WUSM1fHj4llz532DtQrTQHZUp9NZz3NG5mBoTL+i4sIGd0X07t838mOLK2oRyD1qXFwcgeNoYVGBWNzoXeV+fXFmp1GO4itTiIFFi2fT6XRHR6ejx/av+Gl9jx69KyrKN2/5NSs7XalUhod3jx0f5+bq/jj5gaFTHTM2utdHkcuWrhk8JGLihPibt69lZKSeP3v7518WqZTKNav/BAA0WINUKh0a03fSxKmjRsYaTq3RaKKHRcYMG/nlpK8bPMTcn52YcZRGoz17lp2X/+rnFRs6dgzUaDQzZ8dnZKbOnrVo985jXC5v6tRxxSVFYaFdV63cCAA4eOD0sqVrAAA0Ov3kqSO+vn7r1m5mMBh1FTZWg42NTZcuPe7c/buu5L37t2UyWVTU4MYOMfdnJ2YcpVAoFZXlPy1d263bR7a2dmnpKW/fvl4w/6ew0K729g7Tps7kcLgnThxu8ECBo3D6tNkhncMNL6YZaKKG3r36PX2aWVlZYSh5+/Z1nzZt3d08jD8puiA7GhcX9+WXX5pbB+q08vSqa2QZGak0Gq1zcJjhv2QyOSCwc0bGkwYPbOvb/v2NTdTwUc8+DAbj1q1rhqZ8N+lmZGSUqSdFEWLGUQAAvV6fKZHUqtXqPn1D6xfg8wUNH9jQSz5N1MBkMrt1/ej23RsxMSOT7t1SKpWRfaJMPSmKIDuakJBApVInT55sbinmg88XsFislSv+sy4PlWLCzEnTNURE9F/203yxWHTnzo2AgGAnJ2dUTto8Poj5IG9vX7lc7uzs6uLsathSWFTgYM9Hq4ZuXT9isVj37t9++Cjpq8nT0Tpp80DuUePj43HdQAEAXcK7h4d3X7v2p9LSEpGo+uSpo/HxYy9fOQcA8PBsDQC4deva05ys5tVg6Ki7d++dmHhMLpf37tXXmEPMxwfRRgEAq1ZuPHP2xE8rFmRnZ3h6th44MHpo9OcAADdX94+jBu/avSUwoPO6tZubUYOBPr37L1w0s2vXnra2dkYeYiaQ32TCPI6KK9SnE4qGTW+FlQAMObwmN/bH1gyWCYNTXI5jIU2A3OvGx8dbRAkEHYyaM8LLO6YQY+d1d+7caRExEBRAdpRMJuN02ujDxKj7oxZRAkEHGEeJBoyjRAPGUaIB4yjRMCpXilartYgYCAoYlYdh9+7dFhEDQQFkRykUCnysHkcgW/XVV19ZREmjMNkU4j4v3CR6QKWRGEzThqU4iKMMNlmn19dWf3DrK1YWK224VGDirxkfcTToI7tnj8TYarA8zx6LA3qZnL4TH3E0sLcdmQzSblkiw62V8OhShZ0TrX2Yybk7cZONFQDw97EytRpQqCSBK0utIuYFFZVOrihQaDV6Gx65Z3RzHgXFU8ZkAEBxrqKsQCGTaJVSCz3mn5OTQ6VSfXx8LHM6Jodsw6UKPZlOngwjijcAsk87d+60nud1XbyZLt4WXWYwa9Mxpo1NxOfdLHnSloAcR6lUKkw7hiOMysNgESUQdEBuo2q1GqbvxBHIju7cuRPmM8IRMI4SDRhHiQZyG1UqlSqVyiJiICiA7Oju3bv37dtnETEQFEDudel0OoyjOALZ0UmTJllECQQdYBwlGjCOEg0YR4kGjKNEA7nXVSgUCoXJ67FBsALZ0T179hw4cMAiYiAogNzrMplMK3mAAWIMyFZNmDDBIkog6ADjKNGAcZRowDhKNGAcJRrIva5MJpPL5RYRA0EBZEf3799/5MgRi4ixRnCXtMCoOPohz+viLk0/sqOxsbEWUQJBBxhHiQayo/v27Tt48KBFxEBQALnXZbFYH3IcxR0wjhIN5F5XIpFIpVKLiIGgALKjBw4cOHzY7GtDQdACude1sbGBcRRHIDs6btw4iyiBoAOMo0QDxlGiAeMo0YBxlGgg97q1tbUSicQiYiAogOzowYMHP+T7o7gDudflcDgfYByNjIysqanRarUUCkWv1//xxx96vV4gEFy5cgVraQggOzp27FiLKLEuwsPDr169alicnUQiAQD0en1kZCTWupCBcbRhxowZ4+LiUn+Lp6fn55+bffXQlgPjaMN06tQpICCg/pYuXbq0adMGO0XGguwoh8Phck3O8koARowY4er67xLc7u7uI0aMwFqRUcA42iiBgYF+fn5FRUUAgLCwMG9vb6wVGQVyGxWLxTU1NRYRY3WMHTuWz+e7u7uPHj0aay3GgtxGDx8+bPn8usW5isoSlawW8wyT7mE+o5hMZvlz2/LnGOdUt+FS+a4M59YImZSRHeXxeJa8HlVItYlbishUkqMbi0rHflWQqAFDAABKK3g5T1ylzEmpBXp99BS3Jr4Z68pTL6vVXthdEjpAwHdpZk5vwlP6WpF2szI63rUxU60rjp7aVNhloCO0swmcWjEDejuc3lbUWAFkRw8fPnzs2DG0hTVAXpbUTsiwE9ItcC5c49yaRSKRSvIajgTIjvJ4PFtbWzMIe5eKIhXP4YObQG4ePHtaRXHDieCQR0YWG7jLa7VMDnz12CgYNpTGLgSsK45CWo4VxVEIKiD3cnZ2djAPA45AtmrkyJEWUQJBB+ReVyQSiUQii4iBoACyo0eOHDl+/LhFxEBQAMZRogHjKNGAcZRowDhKNJB7XXt7+w/weV38guwoXp6YghhA7nWrqqqqq6stIgb3PH+R06dvaFZWOoYakB09duzYiRMnLCIG9/AdBOPHTRYIhBhqgHEUTfh8wcQJ8dhqwHccHTwkYuKE+Ju3r2VkpJ4/e5vNZl+4ePrsuZP5+a+8vX0j+0R9FvPvxXRe3qszZ4//k/KorKyklafX4MGffTpomGFXfn7unr1bn6QmUyiUDv4BI74Y17FjoGHXvv07rlw5V1Ze6uTkEtI5fMb0uWQy+eXL519NGb15096Dh3YlJd0SCp36RAyYEjeDRCI9f5EzJX7sn7/v6tAhYNHi2TQaLTIyas2aZXKFvEOHgClx37b36wAA0Gq1v/+x5m7STTqNPmDAIF8fv0VLZp89fZPD4bT8O8F3HKXR6SdPHfH19Vu3djODwbh69cLadcv92vkfPnh24oT4Y3/t37xlg6HkH3+uTf7n4Xffzl/1828DB0av/3Xl4+QHAACVSjVzdjyNTt+wfuvqX/4AACxcNFOpVAIAdu9JSDx97OupM4//dXlC7JSr1y6cOnXUsEgVAGDd+uX9+31y5dL9+fOWHT22/+ata+9oo9PpmVlpN25c3rr14MXzd6kU6pq1ywy7jh7bf/5C4rcz5m3depBCoe7dt63ufamWg+84SqFQBI7C6dNmh3QOp1AoZ8+fDAgI/nbGPDs7+9CQLrHj406eOiIWiwAAS5asXrt6U+fgsOCg0KHRn/v6tHv06B4A4O3b19XVVZ/FjPL29vH1abd0yeqlS1ZrNJpaSe3hI3tjx8d1796Lx+X1jYwaGv3F/oM7dTqdId1uRO/+vXv1pdFowUGhTk7Oz58/fUcbmUxWyOWzZy1ycXalUql9+gzIz881rOFw+cq5Xh9F9vooksfljR83mcVmo/idIDvq6upa9/qHFdLWt73hD41Gk52dERbarW5XcHCYVqvNyEgFAOh1ur9OHBwXG9Onb2ifvqEvXj4TiaoAAO7unnZ29qt+WXzw0O6srHQKhRIcFGpjY/P27Wu1Wu3v36muNl9fP7FYVFzy70N4bdu2r9vF4XAlktr3tXl4tmb/v1tcLg8AIJVKNBrNmzf5HToE1hX7qGcfFL8Q5Dg6ZMgQFM+HOoY+0LCKiVar3blr885dm+sXqBZVabXaefOn6/X6KXEzgoPCbGxsvv7m3+T7DAbjtw3bz19I/Ov4wR07N7m5eUyIndKv78dVVRUAACaDWVcPi8UGAMhlMiaTaWiCiNoaLCOVSQ35M+u28LhoPpiH7GhFRQWJROLz+Sie1RxwOBwmk/lx1OBevfrW3+7m6vHsWfbzFznr123pHBxm2Fi/SXl6tp4a/93ECfHJyQ8uXTm78ucfW7fytrHhAADkiv8lFpbLZQAAgcCxweZoPCwmyzA4qttSLULz/QvkH9rx48dPnTqF4inNh7e3r1whDw4KNfzr4B8g4DsKhU6GUCrgOxqK5ea+fPv2teHv16/zLl0+a0je3rNnxNLFq8lk8ouXOW3atKVQKJmZaXWVP32aaW/vYGdn30KRdDqdzxfkv86t25J071YL66wPsqN8Pl8gEKB4SvMx5asZt29fv3DxtFarTU9/smz5/FlzpqpUqtZebUgk0l/HD0okktev8/7ctC6kc3hJaTEAQCSqXr1m2ZaEjYVFBfn5uQcO7tLpdB38A3hcXt++H+8/sOPevdsOVm2GAAAVYElEQVS1ktpLl8+eOXt8+GfoPOjavVuvS5fOpDx5rNPpjh7bL5OhmdINudfFxavqBgICgrduOXDw0O6EhI0qtcq/facVy3+l0+kuzq4Lf1ix/8COwdER7u6ePyxYXlpavOyn+V/Fjd6+7dDM73/Ys3frsb8OAADCQrtuWL/V07M1AGD6tDlbKBuWr/xBo9G4uXmMGzt5xBfopHaaOCG+tKxk1uypbm4eIZ3DY4aNXLd+BVqPFSC/yWSxOHr7ZAWTQ23fxc7cJ8IchUJRVlZi+N0AAA4e2v3X8YOJJ9+9om2C1JtVDCYIj3J4fxeh4iheOHR4d1z8mMTTf4nFomvXLx0/cWjI4M/Qqhy5pQsEAjiviy4TJ8SLxaKLF08nbN0oFDp/FjNq9CjUljKzovdHP5xet+W0qNctLy+vqKgwjzAI+iA7euLEicTERIuIgaAAjKNEA9nR4cOHW0QJBB1gHCUaMI4SDeReVygUwjiKI5AdjYmJsYgSCDog97qlpaVlZWUWEQNBAWRHT506debMGYuIgaCAFcVRFpeiVlvLlKSVo9XoWY1kCrKiOMp3pmfeh2l2jKL8rbxdcMOPIVhRHPXuZFNVqpTVYJ6B1dqpKlHptHoXb2aDe60rjsZMc79zqhSa2gTiCvXjy+XR8Y0+b4vc6zo7O1ssDwPPgTpgrNPx398K3Vl8NybNCvLrWg8KqVZcqaoqVg6f4c60oTRWzIruj9bnZZqkqkQlq9EaUda85OTkUKlUHx8frIUAFo/i6Mrw7mTTdDHkxldSUmJoqehpQ8YnkAMCjShnfrI2HWPa2ER83s2IslYBchxNTEw8d+6cRcRAUMC64iik5SBbNXToUIsogaADcq9bUlJiCKUQXADjKNFA7nVdXFxgHMURyFZFR0dbRAkEHZB73aKiouLiYouIgaAAsqNnzpw5f/68RcRAUADGUaIB4yjRgHGUaMA4SjSQe103NzcYR3EEslWDBw+2iBIIOiD3ugUFBYbVySG4ANnRc+fOXbhwwSJiICgA4yjRgHGUaMA4SjRgHCUayL2uu7s7jKM4AtmqTz/91CJKIOiA3OtKpdIP+W3DS5cu4WtsiOyojY2NUCj85ptvLKLHupg4ceLPP/9s/dmi62PsWxJKpVKn09XPxU14Fi9e3LVr108++QRrIaaB3EYNMBiMly9fvnjxwsx6rIVt27a5u7vjzk4THAUAdOrUKSEh4fbt2+bUYxVcvHjx7du3cXFxWAtpDia/m1ZZWWlnZ0ehNPq2G97Jyspau3btnj17sBbSXPSmc+7cOZ1O14wDrR+RSBQZGYm1ihZhQq9bR0hICL4G9MYzbNgwvCf8buYbwUqlUiKR4GtYj0hsbOzcuXM7dOiAtZAW0Zw2ahj6yuXyjIwMtPVgxsKFC0ePHo13O5vvqGG+99atWzgeQdQjISHBy8srKioKayEo0NI8DOXl5TY2NmxUV+ezMOfPn3/06NGyZcuwFoIOzW+jBhwdHTMzMyUSCUp6LE1aWtrJkycJYydo3tXL+/To0UOhUKBSlSWpqqrq168f1ipQBp3sNxqN5s2bN97e3mj8xixHRETE+fPnbWwQ8sngi5b2ugaoVCqfz8fX0Hfs2LEJCQkEsxM1RwEAtra2ubm5y5cvR6tCs7JgwYLY2Fg/Pz+shaAPyjnHSktLyWSyo6OjoU/j8XhWcrc8JiamoqLCcJth8+bNTCZz0qRJWIsyC6i1UQNOTk5isbiqqqpLly4SiUSj0aSnp6N7imbw8OHDmpoamUzWpUuXM2fOVFRUENVOo54zMhUfH5/g4GDDzZnKysqnT58GBASgfhaTyMrKqq6uJpFIWq126dKlKSkp2OoxKyi30SFDhnTu3LnuXptGo7l//z66p2gGKSkpdcGFTCYHBwcPGzYMa1HmAk1HY2JiiouL6y8wTyKR8vPz1Wo1imcxlZqamrdv39ZXRaFQCgoKiGoqmo6ePHly8uTJrVu3ZrPZOp3OsFGtVmdnZ6N4FlPJzs6WyWSGv3U6HYfD8fb2njJlCt7vmjUGynF0ypQpkydPvnLlysmTJwsLC0tKSioqKp4+fRoYiFlu1ezs7KqqKr1e7+Li4uXlNXjwYGLMyDcG8tVLSZ6yolgpqzU503hpaWlOTs6bN2/s7OwwvEN++vTp2tpaT09PPz8/oVBo6uFsLkXgynBu3XBSeCukKUfVSv3phEISmWTrSGewCPtgUdPIJRqpWEMi6Qd/5Uqh4iDLeqOOqpW601uLg/vwhZ64+Xmaj6JXssyk6mFfu5Ip1m5qoyOjxIQiaGcdrm3YHbrbn92OgyxADTta9EpOo5OhnfVx82GrlPryAiXWQhBo2NGKYhXPgW5xMdYO155WWaTCWgUCDTsqr9XSWShPJxEAFocitfrVhaBtRAM6SjSgo0QDOko0oKNEAzpKNKCjRAM6SjSgo0QDOko0oKNEAzpKNKCjRIPgji5dNu/CxdNYq7AoBHc051kW1hIsTcPPGT28WKVWg8DeDsZXVFlZsXrN0qzsdE9Pr2HRX+Tlv3r0+N7O7UcAABUV5Zu3/JqVna5UKsPDu8eOj3NzdQcAvHz5/Kspozdv2nvw0K6kpFtCoVOfiAFT4maQSCQAQEZG6t592549y3bgC7p26TkhdoohK+HxE4eOHN333bfzly6bFzNs5NdTv79//86Nvy+npadIJLXt/TqOGzs5KChEo9H0j+pq0Mbj2Z4+dV2j0Wzf8eeDh3crKsoCAjoPjf6iS3h3k76slOuVHB45pJ+9SUdZGNTa6Jq1y96+fb1+XcJPS9feTbr5zz8PDcZoNJqZs+MzMlNnz1q0e+cxLpc3deq44pIiAACdTgcArFu/vH+/T65cuj9/3rKjx/bfvHUNAPDmTf7c+d+oNerNm/YuWfTLixc5M2fHG57qptHocrnsyNF9PyxYPmTIcJlMtuLnhRqNZsH8n1au2ODm5rFw0fciUTWVSr10IQkAMGf2otOnrgMANmxcdfLUkc9iRh0+dK5nj4hFi2fdTbqJ1se3HtBxtLKy4tHj+yNHxvq183d0FM6aubCouMCwKy095e3b1wvm/xQW2tXe3mHa1JkcDvfEicOGV1AAABG9+/fu1ZdGowUHhTo5OT9//hQAcO36RRqV9tPStR4erby9fWbN+jEnJ+ve/duGdxxkMtmXk76O7DPA3c2DzWbv2H7ku2/nBweFBgeFxn01QyaTZWamvaNQoVBcuXp+9KgJQwZ/xuPyBn0ytE+fAfv2bUfl41sV6DxTn5f/CgDQqWOQ4b+2tnZBQaElJUWGzpNGo3UODjPsIpPJAYGdMzKe1B3btm37ur85HK5EUgsAyMxM8/PrYGtrZ9ju5uru7OSSlpbSs0eEYUu7tv51R8mk0h07/kxLT6msrDBsEYmr31GYk5Ol0WjCQrvVbQkKDLly5bxcLidYill0HJVKJQAAZr2vhse1NTgqkdSq1eo+fUPrl+fzBXV/13/HqA6JpPbFy2fvHFVdXVn3t6HHBgCUlBR/+/3ksNBui39c5e/fSavVfvxJjwYqlNYCAKZ/++U720XiauhoAzDoDACAVvO/p6qqRVWGP/h8AYvFWrliw3/OSkE4rwNf0InFmjghvv5GW57d+yVv/H1ZrVbPm7uUyWQCAMRiUcMVOggAALNmLnRz86i/3d7OhNEfLkDHUVdXd0Pf6+HRCgBQU1uTmpps+O68vX3lcrmzs6uLs6uhcGFRgYM9QkLBNt6+f/99JSgwxDC8AgDk5+e6u3u+X1IsFnG5PIOdAADDwOp9PDxa0el0CoUSHPRvu6+qqiSRSHUHEgZ0Rkaenq09PFrt2bu1qLiwVlK7ceMqg8cAgC7h3cPDu69d+1NpaYlIVH3y1NH4+LGXr5xrusIvvhin0Wr+3LxeoVC8eZOfsPW3SZNHvH6d935JnzZtKysrzl9I1Gg0Dx4mZWamcmw4ZWUlhuSFjo7ClJRHT1KTWUzWhNgpe/ZuzchIVSgUN29dmzk7/vc/1qDy8a0K1N42nDdnydr1y8eOG+rr025A/0Fsts2rV88Nu1at3Hjm7ImfVizIzs7w9Gw9cGD00OjPm67Nlme7c8fRI0f2To4bVVj41s+vw7w5S9q08X2/ZL9+A1+/ydu9J2Hd+hXh4d3nzVly4NCu/Qd2SmXS6dNmjxk9afeehAcP7x47cnHUyFgfn3aHjuxJTn7A49l28A+YPWsRWh/fekBthkEsFikUCicnZ8N/5877xsaGs2TxL+hJxZ4Pa4Zh0ZLZM2dNuXv3ZnV11d5925+kJn/6aQxalUOMB7U2KhJVr12//PXrvMrK8laeXrHj47p1+whVqdiDizaKWhy1s7NfufxXtGqDNBuC33v5AIGOEg3oKNGAjhIN6CjRgI4SDego0YCOEg3oKNGAjhKNhh1lcSgaDZr564mBRqVn89DPGo4uDTvKd6FXFCgsLsbaKS+Q812sPXFXw466+bDUSq2ozNrza1mS8gIFlUYSejCwFoJAo3E0Ot7t4cVycQWWCcmth6oSZcr1yiFTXLEWgkxT+XVltdoTfxTYOzHsHBlMmw9xDEUCQCbR1lapxBWqmGnuDDYOvgTkHNh5WbLyQoVMrLWUpP+g0+kuX748cOBATM5OIgMWlyJ0Z7T2x81iXCivyYQ6KpUqIiLi3r17WAvBDTjoRiAmAR0lGtBRogEdJRrQUaIBHSUa0FGiAR0lGtBRogEdJRrQUaIBHSUa0FGiAR0lGtBRogEdJRrQUaIBHSUa0FGiAR0lGtBRogEdJRrQUaJh7Y6SSCQ2m421Cjxh7Y7q9XqZTIa1Cjxh7Y5CTAU6SjSgo0QDOko0oKNEAzpKNKCjRAM6SjSgo0QDOko0oKNEAzpKNKCjRAM6SjSgo0TDSjNUTZ069cGDB3WLjxogk8nJycnYicIHVtpGp0+f7urqSv4vTk5OWOvCAVbqqL+/f3BwcP0tWq02JCQEO0W4wUodBQCMGDHC2dm57r9ubm6xsbGYKsIH1utop06d6jfTkJCQNm3aYKoIH1ivowCAkSNHGpqpk5MTbKBGYtWOdujQITAwEAAQHh7u7e2NtRx8gObVS3mBUlqjldVq1Eq9Uo5OhuXy8vLLly8PGjTI3h6dlXkZbAqdQWJzqTY8qsDN2pcRaAYoOJqfLXv+RJKXKbFzZqsUWiqdSmPSdFodSgpRhkQmaxQqjVpLZ1JqyuWtO9i0C+Z4+hHnIe8WOZqbKb19qoLJZTI4DJ7QhkKz6j78fTRKbU25TC1TKqXK3jGCVoTwtZmOqpX6cztLJLV6YRsHhg3NDMIsiqJWVZZbZedAHRKH+0mM5jhalCtP3FLkHerK5BEqDslEytzHRSNneQjcrH1RlyYw2dGKQtX5PaWtOuNg5ZPmkfeoMOYbF1s+Xjse0xzNzZTeOV3dqrOLOSVhT97jwqixjq7eLKyFNAcTxjISkeb60TLC2wkA8ApzO721SK200uF605jQRo9tLBT4OJEpJCPK4h61Qisprhz2Nf5+vsa20QcXqwCV8YHYCQCgMSkKFeXJTRHWQkzGKEd1OpB8rUrYBp1ZG7zg5ONw/3wl1ipMxihHH1+pdmvPN7+YZvLX6VXrN41FvVoyheTia59yoxr1ms2KUY4+fVjDtsflwK+FMG2Z2Y8kWKswDWRHq0pUOj2Jwcbr9VlLYPEYcolWItJgLcQEkFelfvNcZufKMZ+Ch/+ceZicWFL6ysXZN6hT/4+6jTBsX7Sy38D+U2trK6/e3Mlk2LTz7Rb9yUwelw8AUCplB48vfpmb7OLk06PLcPNpAwDYu3HePJP5d+GZ9SwogtxGy96oSGRzTcH/k3rxr8SV7q7tf5iVGBUZdyvp4JmLvxl20WiMG7f30WiM5T9cmzPjaG7+k6s3dxp2HUtcWVH5duqkzbGjVhcWP3/+8oGZ5AEAAIlcXoin1a+RrZLWaKgMcy0w/yA50btVcMzgORwb+7Y+4f37TL774KhUarhmIAkFnpG9Ylksri3PsW2b8MKiZwAAcU15Wua1Pj3Hebj587j8T6OmUylmnF6mMaj46nWNdJRijnNrtZrXbzPa+nap2+LrHarTafNepxn+6+7Wvm4Xi8WTK2oBAFXVhQAAJ6GXYTuJRHJ39TOHPANUBkVagydHkRsfhUomk8wysaBSK3Q67aVrCZeuJdTfXiut+v8/GzivVCYGADAZ/wvtdLoZx+EkEolMxtO8CrKjdCZZrdQwOOiPdVlMDp3GDA3+NKBDZP3tAr57E0fZsG0BAGqNsm6LQilFXVsdaqWGwTZLF2UmkB3l2FLkSnMty+7i7KtSy328/320Wq1RVVcX29k2ddvZ3s4VAPD6bYabS1sAgEqleJmbzOM5mkmhRqnlC/DkKHIcFbrTScBcdyEGDZiWnnXj4T9ntFptbv6T/Ud/2LrnG7WmqbGlna2wtWfgpWsJFZVv1Wrlwb8WmW8oDgAgk3QCFzzdAEf+Ltx82KISc82beLcO/i5+b15+6tJforbv+1aplE0cs5ZGRRi7jvpsibtb+183jV24og+Xww8NGgTM9j5WdZHE3RdP82VG3U3bsSivdYibmUa81oxSqi7JKY39sRXWQkzAqP6qY1eepFJhfjFWh6xa4R+Om9kiA0ZNHQRF2O9dkW/natNYgaSHxy9e29LgLq1WTaE0PE4e/dkyf7+eRktF4ObdA9du7W5wF4vJkytqGtwVF/u7p3uHxuosyqmInuSDlkLLYOwzDHcSK8pKyXxP2wb3yhUSubzhr0wmr2WzuA3u4tg40OlMU9Q2hVxea5iCeB+1WkmjNTy64XIFjYXtirxqzzbk8CgHtBRaBmMd1enA8d8KhX7ORpQlAjodqHxZ8vm3blgLMRljx/1kMogYLnidUmRmPdZC3qO3A8YIsVbRHEy4khN6MEL68AoySs2pxyp4k1bSa5jAVoDLW8ImP4H9Ik12/6LYMxCXv19jyE8piRzO92yHWoC3MCbPtvgGssP7cl49KNCqcfk4axNolNrnSW8+GmyHXzub/yZTVYnq8sEyMo3u6O1AgEc+tWpdRV4VGWg+Hu/EtTfXzWDL0KK3DdPviJPOVgi9bBlcJoePp6myOmrLZSqZsuJ1TY/B/I7dG742wxcovBGc9aDmeYqkOE/u5M3TqHUUGoVCpwGdNSa+AgAAEkmrUms1WhqNXPRS7OHLbtuZ2z684StmPILaW/tatf7tC7lEpJbVanVavazWXDfgWgiLQ6HSSGwelWtH9WjLJuHsJWZkrDSLHKTZEO4n+sEDHSUa0FGiAR0lGtBRogEdJRrQUaLxfxUYkMUItbtqAAAAAElFTkSuQmCC",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RVq-ufWH32lp",
        "outputId": "131e4c48-afac-456e-cae8-8fd283171ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====검색 시작=====\n",
            "=====검색 시작=====\n",
            "Docling implements a linear pipeline of operations, which execute sequentially on each given document (see Fig. 1). Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support downstream operations. Then, the standard model pipeline applies a sequence of AI models independently on every page in the document to extract features and content, such as layout and table structures. Finally, the results from all pages are aggregated and passed through a post-processing stage, which augments metadata, detects the document language, infers reading-order and eventually assembles a typed document object which can be serialized to JSON or Markdown.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Docling provides a straight-forward interface to extend its capabilities, namely the model pipeline. A model pipeline constitutes the central part in the processing, following initial document parsing and preceding output assembly, and can be fully customized by sub-classing from an abstract baseclass ( BaseModelPipeline ) or cloning the default model pipeline. This effectively allows to fully customize the chain of models, add or replace models, and introduce additional pipeline configuration parameters. To use a custom model pipeline, the custom pipeline class to instantiate can be provided as an argument to the main document conversion methods. We invite everyone in the community to propose additional or alternative models and improvements.  \n",
            "Implementations of model classes must satisfy the python Callable interface. The \\_\\_call\\_\\_ method must accept an iterator over page objects, and produce another iterator over the page objects which were augmented with the additional features predicted by the model, by extending the provided PagePredictions data model accordingly.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Converting PDF documents back into a machine-processable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which discards most structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, cloud offerings [3] and most recently, multi-modal vision-language models. As of today, only a handful of open-source tools cover PDF conversion, leaving a significant feature and quality gap to proprietary solutions.  \n",
            "With Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.  \n",
            "Here is what Docling delivers today:  \n",
            "- · Converts PDF documents to JSON or Markdown format, stable and lightning fast\n",
            "- · Understands detailed page layout, reading order, locates figures and recovers table structures\n",
            "- · Extracts metadata from the document, such as title, authors, references and language\n",
            "- · Optionally applies OCR, e.g. for scanned PDFs\n",
            "- · Can be configured to be optimal for batch-mode (i.e high throughput, low time-to-solution) or interactive mode (compromise on efficiency, low time-to-solution)\n",
            "- · Can leverage different accelerators (GPU, MPS, etc).\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Docling provides optional support for OCR, for example to cover scanned PDFs or content in bitmaps images embedded on a page. In our initial release, we rely on EasyOCR [1], a popular thirdparty OCR library with support for many languages. Docling, by default, feeds a high-resolution page image (216 dpi) to the OCR engine, to allow capturing small print detail in decent quality. While EasyOCR delivers reasonable transcription quality, we observe that it runs fairly slow on CPU (upwards of 30 seconds per page).  \n",
            "We are actively seeking collaboration from the open-source community to extend Docling with additional OCR backends and speed improvements.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Docling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecognition model, a code-recognition model and more. This will help improve the quality of conversion for specific types of content, as well as augment extracted document metadata with additional information. Further investment into testing and optimizing GPU acceleration as well as improving the Docling-native PDF backend are on our roadmap, too.  \n",
            "We encourage everyone to propose or implement additional features and models, and will gladly take your inputs and contributions under review . The codebase of Docling is open for use and contribution, under the MIT license agreement and in alignment with our contributing guidelines included in the Docling repository. If you use Docling in your projects, please consider citing this technical report.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "=====검색 완료=====\n",
            "=====추론 시작=====\n",
            "<think>\n",
            "Okay, so I need to figure out how Docling differs from other libraries used for converting PDFs into machine-readable formats like JSON or Markdown. Let me start by reading through the provided document content carefully.\n",
            "\n",
            "First, I see that the main features of Docling are listed towards the end. It mentions things like handling page layout, understanding reading order, detecting figures and tables, extracting metadata such as titles and authors, and supporting OCR for scanned PDFs. It also talks about being optimized for either batch processing or interactive use, with support for different accelerators like GPUs.\n",
            "\n",
            "Looking at how the model pipeline works in Docling, it says you can extend its capabilities by subclassing an abstract base class. This means users can customize the chain of models as needed. Each document is parsed by a PDF backend that extracts text tokens and creates bitmap images for pages. Then AI models are applied independently to each page to extract features like layout and tables.\n",
            "\n",
            "In comparison, other libraries might not offer such flexibility or might have different approaches in handling these aspects. For example, some might rely more on pre-trained models without as much customization options. Docling's emphasis on extensibility seems unique.\n",
            "\n",
            "Another point is the mention of Open-source versus proprietary solutions. The document highlights that only a few open-source tools cover PDF conversion, leaving gaps compared to commercial offerings. Docling addresses this by being permissive under an MIT license and running entirely locally without needing commodity hardware setups beyond what's standard for Python libraries.\n",
            "\n",
            "OCR support in Docling is mentioned as optional but initially uses EasyOCR with high resolution images. The slow performance of OCR on CPU might be a limitation, which could be something other tools handle differently.\n",
            "\n",
            "Putting this together, Docling's main differences are its extensibility, focus on PDF-specific features like layout analysis and table structures, integrated OCR capabilities (though with some limitations), and open-source licensing compared to proprietary solutions. Other libraries might offer similar features but without the same level of customization or may not be as efficient in handling these specific tasks.\n",
            "\n",
            "\n",
            "\n",
            "=====답변 생성 시작=====\n",
            "Docling은 다른 PDF 변환 라이브러리와 비교했을 때 다음과 같은 주요 차이점을 가지고 있습니다:\n",
            "\n",
            "1. **확장성과 커스터마이징**:\n",
            "   - **Docling**은 사용자가 모델 파이프라인을 확장하고 커스터마이징할 수 있는 유연성을 제공합니다. 추상 기반 클래스를 상속받아 파이프라인을 맞춤 설정할 수 있어, 특정 작업에 맞게 모델 체인을 조정할 수 있습니다. 이는 다른 라이브러리들이 제공하는 일반적인 기능보다 훨씬 더 높은 수준의 사용자 정의를 가능하게 합니다.\n",
            "\n",
            "2. **PDF 특화 기능**:\n",
            "   - **페이지 레이아웃 분석** 및 **표 구조 인식** 등 PDF 문서의 고유한 특성을 효과적으로 처리합니다. 이는 단순히 텍스트 추출을 넘어 문서의 구조적 이해를 높이는 데 중점을 두고 있습니다. 다른 라이브러리들이 이러한 세부적인 분석을 제공하지 않거나 덜 강조하는 경우가 많습니다.\n",
            "\n",
            "3. **OCR 지원**:\n",
            "   - **Docling**은 스캔된 PDF나 비트맵 이미지 내의 내용을 처리하기 위해 OCR 기능을 옵션으로 제공합니다. 초기 구현에서는 EasyOCR을 사용하지만, 성능 향상을 위해 커뮤니티의 기여를 적극적으로 환영합니다. 일부 다른 라이브러리들은 OCR 기능을 제공하지 않거나 제한적으로 지원할 수 있습니다.\n",
            "\n",
            "4. **오픈 소스 라이선스**:\n",
            "   - **Docling**은 MIT 라이선스 하에 오픈 소스로 제공되어 사용자들이 자유롭게 사용하고 개선할 수 있습니다. 이는 상용 솔루션이나 제한적인 오픈 소스 도구들과 대조되며, 특히 하드웨어 요구사항이 낮아 로컬 환경에서 쉽게 실행할 수 있습니다.\n",
            "\n",
            "5. **효율성과 성능**:\n",
            "   - **Docling**은 배치 처리와 인터랙티브 모드 모두에서 최적화되어 있으며, GPU와 같은 가속기 지원을 통해 빠른 처리 속도를 제공합니다. 이는 다른 라이브러리들이 제공하는 기능과 비교했을 때 더 높은 효율성을 자랑합니다.\n",
            "\n",
            "이러한 특징들로 인해 Docling은 PDF 문서를 기계 판독 가능한 형식으로 변환하는 데 있어 높은 유연성, 특화된 기능, 그리고 오픈 소스의 이점을 결합한 독특한 솔루션을 제공합니다.\n",
            "\n",
            "\n",
            "=====답변 생성 완료=====\n"
          ]
        }
      ],
      "source": [
        "input={\"query\":\"Docling이 다른 라이브러리와 다른 점이 무엇인지 설명해줘\"}\n",
        "config={\"configurable\": {\"thread_id\": 0}}\n",
        "\n",
        "async for event in app.astream_events(\n",
        "    input=input, stream_mode=\"events\", version=\"v2\",config=config\n",
        "    ):\n",
        "\n",
        "    kind = event[\"event\"]\n",
        "\n",
        "    if kind == \"on_chat_model_stream\":\n",
        "        chunk = event[\"data\"][\"chunk\"].content\n",
        "        print(chunk, end=\"\", flush=True)\n",
        "\n",
        "    elif kind == \"on_retriever_end \":\n",
        "        print(event)\n",
        "\n",
        "    elif kind == \"on_chat_model_end\":\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZxSP3PMT32lp",
        "outputId": "e5c56a38-d692-4384-f34e-4a02e0204508"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'documents'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m snap=app.get_state(config)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msnap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "\u001b[31mKeyError\u001b[39m: 'documents'"
          ]
        }
      ],
      "source": [
        "snap=app.get_state(config)\n",
        "snap.values['documents']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "StateSnapshot(values={}, next=(), config={'configurable': {'thread_id': '0'}}, metadata=None, created_at=None, parent_config=None, tasks=(), interrupts=())"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "snap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
