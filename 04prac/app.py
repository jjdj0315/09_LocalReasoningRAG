# app.py

import streamlit as st
from dotenv import load_dotenv

from utils.session import session_control
from utils.uuid import random_uuid
from utils.create_dir import create_dir  # create_dir() í˜¸ì¶œ
from utils.creat_compression_retriever import creat_compression_retriever
from utils.upload import upload_file  # upload_file() í˜¸ì¶œ
from utils.node import create_app
from utils.add_message import add_message
from utils.print_messages import print_messages
from utils.handler import stream_handler  # stream_handler ì„í¬íŠ¸

load_dotenv()
session_control()
create_dir()  # ë””ë ‰í† ë¦¬ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ

st.title("LOCAL RAG LLM")
st.markdown("ì˜¨í”„ë¼ë¯¸ìŠ¤ RAG LLMì…ë‹ˆë‹¤., ë©€í‹°í„´ëŒ€í™”ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    # ì´ˆê¸°í™” ë²„íŠ¼
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")

    st.markdown("# **made by JDJ**")

    # ë¡œë” ì„ íƒ
    selected_loader = st.radio(
        "ë¡œë” ì„ íƒ", ["docling", "PDFPlumber"], index=0  # "ì •ëŒ€ì§„" ì˜µì…˜ì€ ì œê±°
    )

    # íŒŒì¼ ì—…ë¡œë“œ
    file = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])

    # ì„¤ì • ë²„íŠ¼
    apply_btn = st.button("ì„¤ì • ì™„ë£Œ", type="primary")


# ì´ˆê¸°í™” ë²„íŠ¼
if clear_btn:
    st.session_state["messages"] = []
    st.session_state["thread_id"] = random_uuid()
    st.session_state["app"] = None
    st.session_state["config"] = None
    st.session_state["compression_retriever"] = None  # retrieverë„ ì´ˆê¸°í™”
    st.success("ëŒ€í™” ë° ì„¤ì •ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ê²½ê³ ë©”ì‹œì§€ë¥¼ ë„ìš°ê¸° ìœ„í•œ ë¹ˆ ì˜ì—­
warning_msg = st.empty()

# ì´ì „ ëŒ€í™”ê¸°ë¡ì¶œë ¥
print_messages()  # ì—¬ê¸°ì— ìœ„ì¹˜í•´ì•¼ í•¨ (ë©”ì‹œì§€ ì…ë ¥ ì „ì— ì´ë¯¸ ì¶œë ¥ë˜ì–´ ìˆì–´ì•¼ í•¨)


# ì„¤ì • ë²„íŠ¼ì´ ëˆŒë¦¬ë©´
if apply_btn:
    if file:
        with st.spinner("ë¬¸ì„œ ì²˜ë¦¬ ë° RAG ì•± ì„¤ì • ì¤‘..."):
            FILE_PATH = upload_file(file)  # íŒŒì¼ ì—…ë¡œë“œ ìœ í‹¸ í•¨ìˆ˜ ì‚¬ìš©
            st.session_state["compression_retriever"] = creat_compression_retriever(
                FILE_PATH, selected_loader
            )  # ì´ ë¶€ë¶„ì—ì„œ retrieverê°€ ì„¸ì…˜ì— ì €ì¥ë¨

            # appì€ retrieverê°€ ìƒì„±ëœ í›„ì— ìƒì„±ë˜ì–´ì•¼ í•¨
            st.session_state["app"] = create_app()
            st.session_state["config"] = {
                "configurable": {"thread_id": st.session_state["thread_id"]}
            }
            st.success("RAG ì•± ì„¤ì • ì™„ë£Œ!")
    else:
        warning_msg.warning("PDF íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”")  # ì´ user_inputì´ ì‚¬ìš©ë˜ì–´ì•¼ í•¨.


if user_input:  # ìƒˆë¡œìš´ user_input ë³€ìˆ˜ ì‚¬ìš©
    # ì•±ì´ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if (
        st.session_state.get("app") is not None
        and st.session_state.get("config") is not None
    ):

        # ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€ë¥¼ ë¨¼ì € session_stateì— ì¶”ê°€í•˜ê³  í™”ë©´ì— í‘œì‹œ
        add_message("user", user_input)
        st.chat_message("user").write(user_input)

        # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ê°€ í‘œì‹œë  ê³µê°„
        with st.chat_message("assistant"):
            container = st.empty()  # ìŠ¤íŠ¸ë¦¬ë° ë©”ì‹œì§€ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.

            inputs = {
                "query": user_input,
                "messages": [
                    ("human", user_input)
                ],  # ëŒ€í™” ê¸°ë¡ (LangGraph messages í•„ë“œ)
                "documents": [],
                "thinking": "",
                "answer": "",
                "mode": "",
            }

            try:
                # LangGraph ì•±ì„ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ ì‹¤í–‰
                # stream_mode="updates"ë¡œ ë…¸ë“œ ìƒíƒœ ë³€í™”ë¥¼ ìŠ¤íŠ¸ë¦¬ë° ë°›ìŒ
                langgraph_stream_generator = st.session_state["app"].stream(
                    inputs,
                    st.session_state["config"],
                    stream_mode="updates",  # <-- "updates" ëª¨ë“œ ì‚¬ìš©
                )

                # stream_handlerë¥¼ í˜¸ì¶œí•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ ì²˜ë¦¬ ë° ìµœì¢… ê²°ê³¼ ë°˜í™˜
                retrieved_docs, final_answer, final_thinking = stream_handler(
                    container, langgraph_stream_generator
                )

                # ìŠ¤íŠ¸ë¦¬ë°ì´ ì™„ë£Œëœ í›„, ìµœì¢… ê²°ê³¼ë“¤ì„ session_state["messages"]ì— ì¶”ê°€
                # 1. ê²€ìƒ‰ëœ ë¬¸ì„œ ê²°ê³¼ ì¶”ê°€ (Tool Result íƒ€ì…ìœ¼ë¡œ)
                if retrieved_docs:
                    add_message(
                        "assistant",
                        retrieved_docs,  # Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ add_messageë¡œ ì „ë‹¬
                        "tool_result",
                        "ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼",
                    )

                # 2. ì¶”ë¡  ê³¼ì • ì¶”ê°€ (ì¼ë°˜ í…ìŠ¤íŠ¸ íƒ€ì…ìœ¼ë¡œ)
                if final_thinking:
                    add_message(
                        "assistant",
                        f"**ğŸ§  ì¶”ë¡  ê³¼ì •:**\n{final_thinking}",
                        "text",
                        "ì¶”ë¡  ê³¼ì •",  # tool_nameì— ìœ ì‚¬í•˜ê²Œ ì¶”ë¡ ê³¼ì •ì„ì„ ëª…ì‹œ
                    )

                # 3. ìµœì¢… LLM ë‹µë³€ ì¶”ê°€
                if final_answer:
                    add_message("assistant", final_answer, "text")  # ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€

            except Exception as e:
                error_message = f"ì˜¤ë¥˜ ë°œìƒ: {e}"
                st.error(f"LangGraph ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                add_message("assistant", error_message, "text")  # ì˜¤ë¥˜ ë©”ì‹œì§€ë„ ì €ì¥

    else:
        warning_msg.warning("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì„¤ì •ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
