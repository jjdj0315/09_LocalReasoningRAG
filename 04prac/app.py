# app.py

import streamlit as st
from dotenv import load_dotenv

from utils.session import session_control
from utils.uuid import random_uuid
from utils.create_dir import create_dir
from utils.creat_compression_retriever import creat_compression_retriever
from utils.upload import upload_file
from utils.node import create_app
from utils.add_message import add_message
from utils.print_messages import print_messages
from utils.handler import stream_handler

load_dotenv()
session_control()
create_dir()

st.title("LOCAL RAG LLM")
st.markdown("ì˜¨í”„ë¼ë¯¸ìŠ¤ RAG LLMì…ë‹ˆë‹¤., ë©€í‹°í„´ëŒ€í™”ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")
    st.markdown("# **made by JDJ**")
    selected_loader = st.radio("ë¡œë” ì„ íƒ", ["docling", "PDFPlumber"], index=0)
    file = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])
    apply_btn = st.button("ì„¤ì • ì™„ë£Œ", type="primary")


if clear_btn:
    st.session_state["messages"] = []
    st.session_state["thread_id"] = random_uuid()
    st.session_state["app"] = None
    st.session_state["config"] = None
    st.session_state["compression_retriever"] = None
    st.success("ëŒ€í™” ë° ì„¤ì •ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

warning_msg = st.empty()
print_messages()

if apply_btn:
    if file:
        with st.spinner("ë¬¸ì„œ ì²˜ë¦¬ ë° RAG ì•± ì„¤ì • ì¤‘..."):
            FILE_PATH = upload_file(file)
            st.session_state["compression_retriever"] = creat_compression_retriever(
                FILE_PATH, selected_loader
            )
            st.session_state["app"] = create_app()
            st.session_state["config"] = {
                "configurable": {"thread_id": st.session_state["thread_id"]}
            }
            st.success("RAG ì•± ì„¤ì • ì™„ë£Œ!")
    else:
        warning_msg.warning("PDF íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")


user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”")


if user_input:
    if (
        st.session_state.get("app") is not None
        and st.session_state.get("config") is not None
    ):

        add_message("user", user_input)
        st.chat_message("user").write(user_input)

        with st.chat_message("assistant"):
            # ê° UI ìš”ì†Œë¥¼ ìœ„í•œ placeholderë¥¼ ëª…ì‹œì ìœ¼ë¡œ ìƒì„±
            # ìˆœì„œê°€ ì¤‘ìš”í•©ë‹ˆë‹¤. Streamlitì€ ì½”ë“œ ìˆœì„œëŒ€ë¡œ UIë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
            node_status_placeholder = (
                st.empty()
            )  # "ë¶„ë¥˜ ì¤‘", "ê²€ìƒ‰ ì¤‘" ë“±ì˜ ìƒíƒœ ë©”ì‹œì§€
            retrieved_docs_expander_placeholder = st.empty()  # ê²€ìƒ‰ëœ ë¬¸ì„œ expander
            thinking_placeholder = st.empty()  # ì¶”ë¡  ê³¼ì • ìŠ¤íŠ¸ë¦¬ë°
            answer_placeholder = st.empty()  # ìµœì¢… ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°

            inputs = {
                "query": user_input,
                "messages": [("human", user_input)],
                "documents": [],
                "thinking": "",
                "answer": "",
                "mode": "",
            }

            try:
                langgraph_stream_generator = st.session_state["app"].stream(
                    inputs, st.session_state["config"], stream_mode="updates"
                )

                # stream_handlerì— ëª¨ë“  placeholderë¥¼ ì „ë‹¬
                retrieved_docs, final_answer, final_thinking = stream_handler(
                    node_status_placeholder,
                    retrieved_docs_expander_placeholder,
                    thinking_placeholder,
                    answer_placeholder,
                    langgraph_stream_generator,
                )

                # ìŠ¤íŠ¸ë¦¬ë°ì´ ì™„ë£Œëœ í›„, ìµœì¢… ê²°ê³¼ë“¤ì„ session_state["messages"]ì— ì¶”ê°€
                # ì´ë•ŒëŠ” ê° placeholderê°€ ì´ë¯¸ ìµœì¢… ë‚´ìš©ì„ í‘œì‹œí–ˆìœ¼ë¯€ë¡œ,
                # add_messageëŠ” ëŒ€í™” ê¸°ë¡ ì €ì¥ì„ ìœ„í•œ ìš©ë„ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.

                if retrieved_docs:
                    add_message(
                        "assistant",
                        retrieved_docs,
                        "tool_result",
                        "ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼",
                    )

                if final_thinking:
                    add_message(
                        "assistant",
                        f"**ğŸ§  ì¶”ë¡  ê³¼ì •:**\n{final_thinking}",
                        "text",
                        "ì¶”ë¡  ê³¼ì •",
                    )

                if final_answer:
                    add_message("assistant", final_answer, "text")

            except Exception as e:
                error_message = f"ì˜¤ë¥˜ ë°œìƒ: {e}"
                st.error(f"LangGraph ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                add_message("assistant", error_message, "text")

    else:
        warning_msg.warning("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì„¤ì •ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
