# utils/handler.py
import streamlit as st
import json
import time  # time ëª¨ë“ˆ ì¶”ê°€
from langchain_core.documents import Document  # Document íƒ€ì… ì„í¬íŠ¸


def format_search_result(results):
    """
    RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•˜ê±°ë‚˜,
    ì´ì „ Perplexity ì•±ì˜ ì›¹ ê²€ìƒ‰ ê²°ê³¼(JSON ë¬¸ìì—´)ë¥¼ íŒŒì‹±í•˜ì—¬ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    """
    # RAG ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ (List[Document]) ì²˜ë¦¬
    if isinstance(results, list) and all(isinstance(r, Document) for r in results):
        answer = ""
        for i, doc in enumerate(results):
            source_name = doc.metadata.get("source", "ì¶œì²˜ ì—†ìŒ")
            # íŒŒì¼ ê²½ë¡œì¼ ê²½ìš° íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
            if isinstance(source_name, str) and "/" in source_name:
                source_name = source_name.split("/")[-1]

            answer += f"**[{i+1}] {source_name}**\n"
            # ë¬¸ì„œ ë‚´ìš©ì„ ìµœëŒ€ 300ìë¡œ ìë¥´ê³  ì¤„ë°”ê¿ˆ ì¶”ê°€
            answer += f"```\n{doc.page_content[:300]}...\n```\n\n"
        return answer
    else:
        # ì´ì „ Perplexity ì•±ì—ì„œ ì‚¬ìš©í•˜ë˜ JSON ë¬¸ìì—´ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ (ì›¹ ê²€ìƒ‰)
        try:
            results_json = json.loads(results)
            answer = ""
            for result in results_json:
                answer += f'**[{result["title"]}]({result["url"]})**\n\n'
                answer += f'{result["content"]}\n\n'
                answer += f'ì‹ ë¢°ë„: {result["score"]}\n\n'
                answer += "\n-----\n"
            return answer
        except (json.JSONDecodeError, TypeError):
            # JSONì´ ì•„ë‹ˆê±°ë‚˜ ì˜ˆìƒì¹˜ ëª»í•œ í˜•ì‹ì¼ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
            return str(results)


# get_current_tool_message í•¨ìˆ˜ëŠ” ì´ RAG ì•±ì—ì„œëŠ” ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°í•˜ê±°ë‚˜ ê·¸ëŒ€ë¡œ ë‘ì–´ë„ ë©ë‹ˆë‹¤.
# (Perplexity í´ë¡  ì•±ì—ì„œ ì‚¬ìš©í•˜ë˜ í•¨ìˆ˜)


def stream_handler(
    node_status_placeholder,
    retrieved_docs_expander_placeholder,
    thinking_placeholder,
    answer_placeholder,
    langgraph_app_stream_generator,
):
    """
    LangGraph ì•±ì˜ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ê³  Streamlit UIì— ì ì§„ì ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
    ê° ë…¸ë“œì˜ ì‹¤í–‰ ìƒíƒœë¥¼ í‘œì‹œí•˜ê³ , ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ìµœì¢… ë‹µë³€ì„ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
    (invoke()ë¡œ í•œ ë²ˆì— ë°›ì€ í›„ ë¬¸ìì—´ì„ í•œ ê¸€ìì”© ì¶œë ¥í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ë¥¼ ëƒ…ë‹ˆë‹¤.)

    Args:
        node_status_placeholder (st.empty): ë…¸ë“œ ìƒíƒœ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•  ì»¨í…Œì´ë„ˆ.
        retrieved_docs_expander_placeholder (st.empty): ê²€ìƒ‰ ë¬¸ì„œ expanderë¥¼ í‘œì‹œí•  ì»¨í…Œì´ë„ˆ.
        thinking_placeholder (st.empty): ì¶”ë¡  ê³¼ì •ì„ ìŠ¤íŠ¸ë¦¬ë°í•  ì»¨í…Œì´ë„ˆ.
        answer_placeholder (st.empty): ìµœì¢… ë‹µë³€ì„ ìŠ¤íŠ¸ë¦¬ë°í•  ì»¨í…Œì´ë„ˆ.
        langgraph_app_stream_generator (iterator): app.stream()ì´ ë°˜í™˜í•˜ëŠ” ì œë„ˆë ˆì´í„°.

    Returns:
        tuple: (list_of_retrieved_documents, final_answer_string, final_thinking_string)
    """
    current_agent_answer = ""
    current_thinking_content = ""
    retrieved_documents = []  # Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ë³€ìˆ˜

    for chunk in langgraph_app_stream_generator:
        # print(f"DEBUG: Handler received chunk: {chunk}") # ë””ë²„ê¹…ìš©
        for node_name, node_output in chunk.items():
            # ë…¸ë“œ ìƒíƒœ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
            if node_name == "classify":
                node_status_placeholder.info("ğŸ” ì§ˆë¬¸ ë¶„ë¥˜ ì¤‘...")
            elif node_name == "retrieve":
                node_status_placeholder.info("ğŸ“š ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
            elif node_name == "reasoning":
                node_status_placeholder.info("ğŸ¤” ì¶”ë¡  ê³¼ì • ìƒì„± ì¤‘...")
            elif node_name == "generate":
                node_status_placeholder.info("ğŸ’¬ ë‹µë³€ ìƒì„± ì¤‘...")
            elif node_name == "__end__":
                node_status_placeholder.empty()  # ëª¨ë“  ë…¸ë“œ ì™„ë£Œ í›„ ìƒíƒœ ë©”ì‹œì§€ ì§€ìš°ê¸°

            # ê° ë…¸ë“œë³„ ì²˜ë¦¬
            if node_name == "retrieve":
                if "documents" in node_output and node_output["documents"]:
                    retrieved_documents = node_output["documents"]
                    with retrieved_docs_expander_placeholder.expander(
                        "ğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ"
                    ):  # expander ì•ˆì— ë¬¸ì„œ ë‚´ìš© í‘œì‹œ
                        st.markdown(format_search_result(retrieved_documents))
                    node_status_placeholder.success("âœ… ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ")

            elif node_name == "reasoning":
                if "thinking" in node_output:
                    current_thinking_content = node_output["thinking"]
                    # ì¶”ë¡  ê³¼ì •ì„ í•œ ê¸€ìì”© ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼
                    full_thinking_text = ""
                    for char in current_thinking_content:
                        full_thinking_text += char
                        thinking_placeholder.markdown(
                            f"**ğŸ§  ì¶”ë¡  ê³¼ì •:**\n{full_thinking_text}"
                        )
                        time.sleep(0.02)  # ê¸€ìë§ˆë‹¤ ì§€ì—° ì‹œê°„ (ì¡°ì ˆ ê°€ëŠ¥)
                    node_status_placeholder.success("âœ… ì¶”ë¡  ê³¼ì • ì™„ë£Œ")

            elif node_name == "generate":
                if "answer" in node_output:
                    current_agent_answer = node_output["answer"]
                    # ìµœì¢… ë‹µë³€ì„ í•œ ê¸€ìì”© ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼
                    full_answer_text = ""
                    for char in current_agent_answer:
                        full_answer_text += char
                        answer_placeholder.markdown(full_answer_text)
                        time.sleep(0.02)  # ê¸€ìë§ˆë‹¤ ì§€ì—° ì‹œê°„ (ì¡°ì ˆ ê°€ëŠ¥)
                    node_status_placeholder.success("âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")

    return retrieved_documents, current_agent_answer, current_thinking_content
