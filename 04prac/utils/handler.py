# utils/handler.py

import streamlit as st
import json
from langchain_core.messages import ChatMessage
from langchain_core.documents import Document
from utils.dataclass import ChatMessageWithType


def format_search_result(results):
    """
    RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    """
    if isinstance(results, list) and all(isinstance(r, Document) for r in results):
        answer = ""
        for i, doc in enumerate(results):
            # ì¶œì²˜ì— íŒŒì¼ëª…ë§Œ í‘œì‹œë˜ë„ë¡ ìˆ˜ì •
            source_name = doc.metadata.get("source", "ì¶œì²˜ ì—†ìŒ").split("/")[
                -1
            ]  # íŒŒì¼ ê²½ë¡œì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
            answer += f"**[{i+1}] {source_name}**\n"
            answer += (
                f"```\n{doc.page_content[:300]}...\n```\n\n"  # ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ë‚´ìš© í‘œì‹œ
            )
        return answer
    else:
        return str(results)


# stream_handlerì˜ ì¸ìë¥¼ ë³€ê²½í•˜ì—¬ ê° ì»¨í…Œì´ë„ˆë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë°›ìŒ
def stream_handler(
    node_status_placeholder,
    retrieved_docs_expander_placeholder,  # ê²€ìƒ‰ ê²°ê³¼ expanderë¥¼ ìœ„í•œ placeholder
    thinking_placeholder,
    answer_placeholder,
    langgraph_app_stream_generator,
):
    """
    LangGraph ì•±ì˜ ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ê³  Streamlit UIì— ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
    ê° ë…¸ë“œì˜ ì‹¤í–‰ ìƒíƒœë¥¼ í‘œì‹œí•˜ê³ , ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ìµœì¢… ë‹µë³€ì„ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.

    Args:
        node_status_placeholder (st.empty): ë…¸ë“œ ìƒíƒœ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•  ì»¨í…Œì´ë„ˆ.
        retrieved_docs_expander_placeholder (st.empty): ê²€ìƒ‰ ë¬¸ì„œ expanderë¥¼ í‘œì‹œí•  ì»¨í…Œì´ë„ˆ.
        thinking_placeholder (st.empty): ì¶”ë¡  ê³¼ì •ì„ ìŠ¤íŠ¸ë¦¬ë°í•  ì»¨í…Œì´ë„ˆ.
        answer_placeholder (st.empty): ìµœì¢… ë‹µë³€ì„ ìŠ¤íŠ¸ë¦¬ë°í•  ì»¨í…Œì´ë„ˆ.
        langgraph_app_stream_generator (iterator): app.stream()ì´ ë°˜í™˜í•˜ëŠ” ì œë„ˆë ˆì´í„°.

    Returns:
        tuple: (list_of_tool_results, final_answer_string, final_thinking_string)
    """
    current_agent_answer_buffer = ""
    current_thinking_buffer = ""
    retrieved_documents = []

    # ë…¸ë“œë³„ë¡œ ìƒíƒœ ë©”ì‹œì§€ë¥¼ ë§¤í•‘
    node_messages = {
        "classify": "ğŸ” ì§ˆë¬¸ ë¶„ë¥˜ ì¤‘...",
        "retrieve": "ğŸ“š ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...",
        "reasoning": "ğŸ¤” ì¶”ë¡  ê³¼ì • ìƒì„± ì¤‘...",
        "generate": "ğŸ’¬ ë‹µë³€ ìƒì„± ì¤‘...",
    }

    for chunk in langgraph_app_stream_generator:
        # chunkëŠ” { "node_name": state_delta } í˜•íƒœ
        for node_name, node_output in chunk.items():
            # ë…¸ë“œ ìƒíƒœ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
            if node_name in node_messages:
                node_status_placeholder.info(node_messages[node_name])

            if node_name == "retrieve":
                if "documents" in node_output and node_output["documents"]:
                    retrieved_documents = node_output["documents"]
                    with (
                        retrieved_docs_expander_placeholder
                    ):  # ì „ë‹¬ë°›ì€ placeholder ì‚¬ìš©
                        with st.expander("âœ… ê²€ìƒ‰ëœ ë¬¸ì„œ"):
                            st.markdown(format_search_result(retrieved_documents))
                    node_status_placeholder.empty()  # ê²€ìƒ‰ ì™„ë£Œ í›„ ìƒíƒœ ë©”ì‹œì§€ ì œê±°

            elif node_name == "reasoning":
                if "thinking" in node_output:
                    current_thinking_buffer = node_output["thinking"]
                    with thinking_placeholder:  # ì¶”ë¡  ê³¼ì • ì „ìš© í”Œë ˆì´ìŠ¤í™€ë”ì— ìŠ¤íŠ¸ë¦¬ë°
                        st.markdown(f"**ğŸ§  ì¶”ë¡  ê³¼ì •:**\n{current_thinking_buffer}")

            elif node_name == "generate":
                if "answer" in node_output:
                    current_agent_answer_buffer = node_output["answer"]
                    answer_placeholder.markdown(
                        current_agent_answer_buffer
                    )  # ìµœì¢… ë‹µë³€ í”Œë ˆì´ìŠ¤í™€ë”ì— ìŠ¤íŠ¸ë¦¬ë°

            # ëª¨ë“  ë…¸ë“œ ì™„ë£Œ ì‹œ ìƒíƒœ ë©”ì‹œì§€ ì œê±° (generate ë…¸ë“œ ì´í›„ì— ë°œìƒ)
            if node_name == "__end__":
                node_status_placeholder.empty()
                thinking_placeholder.empty()  # ì¶”ë¡  ê³¼ì • í”Œë ˆì´ìŠ¤í™€ë”ë„ ì œê±°
                # answer_placeholderëŠ” ë‹µë³€ì´ ìµœì¢… ì¶œë ¥ë˜ë¯€ë¡œ ë¹„ìš°ì§€ ì•ŠìŒ.

    # ìŠ¤íŠ¸ë¦¬ë°ì´ ëª¨ë‘ ëë‚œ í›„, ìµœì¢… ê²°ê³¼ë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    return retrieved_documents, current_agent_answer_buffer, current_thinking_buffer
